1. Цели и предпосылки
   
Бизнес-цель.
-	Автоматизировать анализ тональности и токсичности комментариев в соцсети (до 500 000 в день), снизить задержку модерации, уменьшить субъективность и риск штрафов со стороны РКН.

Почему ML?
- Скорость: от миллисекунд на комментарий вместо ручного разбора.

- Масштабируемость: рост числа комментариев не ведёт к экспоненциальному росту затрат.

- Консистентность: единая модель вместо разных решений разных модераторов.

Бизнес-требования и ограничения.

- Обработка пиков до 20+ запросов в секунду.

- FP (ложноположительных) ≤ 5% для токсичных комментариев.

- SLA uptime ≥ 99.9%, latency end-to-end ≤ 300 мс.

Функциональные требования.

  1.	Классификация тональности: позитив/нейтраль/негатив.

  2.	Детекция токсичности: бинарная метка + уверенность.

  3.	Генерация алертов для модераторов.

  4.	Хранение результатов в БД для отчётности.

Нефункциональные требования.

- GDPR-совместимость: удаление персональных данных старше 30 дн.

- Масштабируемость через Kubernetes + авто-скейлинг.

- Мониторинг через Prometheus/Grafana.
  
2. Методология

Тип решения.

- Задача классификации текста: трансформерная модель (BERT/RoBERTa) для тональности и токсичности.

Необходимые данные.

- Комментарии + ручная разметка тональности и токсичности (минимум 100 000 примеров).

- Контекст (текст поста, историю пользователя) — для будущего расширения.

Метрики ML.

- Precision и Recall для классов «toxicity» и «negative».

- F1-score негативного класса ≥ 0.9.

- ROC-AUC для токсичности ≥ 0.95.

- Latency inference ≤ 200 мс.

Связь с бизнесом.

- Снижение времени модерации на 70%.

- Сокращение ручной работы модераторов.

- Минимизация штрафов за пропуск запрещённого контента.

Риски и меры.

- Bias в разметке → двойная разметка, метрика κ (Cohen’s kappa).

- Дрейфт языка → ежемесячный ретренинг на свежих данных.

- Неполнота словаря → дообучение токенизатора, подбор стоп-слов.

3. Подготовка пилота

Процесс пилота.

  1.	Собрать и разметить 100 000 комментариев.

  2.	Обучить прототип на GPU.

  3.	Деплой в тестовый кластер, прогон реальных потоков (10% трафика).

  4.	Сравнить решения модераторов vs. ML: метрики precision/recall, latency.

Критерии успеха.

- ML-модель по toxic-классу: Precision ≥ 90%, Recall ≥ 85%.

- Latency ≤ 200 мс.

- Удовлетворённость модераторов (опрос).

MVP vs техдолг.

- MVP: базовый пайплайн (Kafka → ETL → ModelService → AlertsDB → Dashboard).

- Техдолг: автоматическое дообучение, мультиязычность, Explainable AI-модули.

4. Внедрение в production

Архитектура.

- Kafka для сбора, Flink/Beam для ETL, HDFS/S3 для raw, Redis feature store.

- Training на GPU-нодах, MLflow registry.

- Inference в REST/gRPC-сервисе на CPU-скейлах.

- Alerts в PostgreSQL, мониторинг через Prometheus+Grafana.

Инфраструктура и масштабируемость.

- Kubernetes-кластер с авто-скейлингом (HPA).

- GPU-пулы для обучения, CPU-пулы для inference.

- Плюсы: отказоустойчивость, быстрое масштабирование. Минусы: сложность эксплуатации.

Требования к SLA/RPS/Latency.

- Uptime ≥ 99.9%.

- RPS ≥ 20.

- P95 latency ≤ 300 мс.

Операционные риски.

- Пики нагрузки → буферизация в Kafka + авто-скейлинг.

- Обновления модели → канареечный релиз.

- Сбоев в инфраструктуре → резервирование зон и бэкапы
